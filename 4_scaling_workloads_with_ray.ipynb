{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from pathlib import Path\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "bucket = sess.default_bucket()  # default bucket name\n",
    "account_id = sess.account_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_location = \"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\"\n",
    "output_location = f\"s3://{bucket}/fico_ml_workshop/aggregation-job/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_RAY = True\n",
    "\n",
    "job = PyTorch(\n",
    "    source_dir=\"ray_script\",\n",
    "    entry_point=\"compute_aggregations.py\",\n",
    "    framework_version=\"2.2\",\n",
    "    py_version=\"py310\",\n",
    "    role=role,\n",
    "    environment={\"USE_RAY\": str(USE_RAY)},\n",
    "    hyperparameters={\n",
    "        \"input_data_location\": input_data_location,\n",
    "        \"output_data_location\": output_location,\n",
    "    },\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count = 3 if USE_RAY else 1,\n",
    "    max_run=1000,\n",
    "    keep_alive_period_in_seconds=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2024-09-11-18-24-14-866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 18:24:20 Starting - Found matching resource for reuse..bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-09-11 18:24:33,141 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-09-11 18:24:33,142 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-09-11 18:24:33,143 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-09-11 18:24:33,153 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-09-11 18:24:33,155 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-09-11 18:24:33,165 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-09-11 18:24:33,166 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-09-11 18:24:33,167 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-09-11 18:24:33,177 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-09-11 18:24:33,179 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-09-11 18:24:33,155 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-09-11 18:24:33,155 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-09-11 18:24:33,156 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-09-11 18:24:33,166 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-09-11 18:24:33,168 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2024-09-11 18:24:34,522 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\n",
      "2024-09-11 18:24:34,475 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\n",
      "2024-09-11 18:24:34,463 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\n",
      "Collecting ray (from -r requirements.txt (line 1))\n",
      "Downloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting awswrangler[modin,ray] (from -r requirements.txt (line 2))\n",
      "Downloading awswrangler-3.9.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (3.14.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (4.22.0)\n",
      "Collecting ray (from -r requirements.txt (line 1))\n",
      "Downloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting awswrangler[modin,ray] (from -r requirements.txt (line 2))\n",
      "Downloading awswrangler-3.9.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (3.14.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (4.22.0)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray->-r requirements.txt (line 1))\n",
      "Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (6.0.1)\n",
      "Collecting aiosignal (from ray->-r requirements.txt (line 1))\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting ray (from -r requirements.txt (line 1))\n",
      "Downloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting awswrangler[modin,ray] (from -r requirements.txt (line 2))\n",
      "Downloading awswrangler-3.9.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (3.14.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (4.22.0)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray->-r requirements.txt (line 1))\n",
      "Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (6.0.1)\n",
      "Collecting aiosignal (from ray->-r requirements.txt (line 1))\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting frozenlist (from ray->-r requirements.txt (line 1))\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (2.32.2)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.20.32 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.34.114)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.23.32 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.34.114)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (16.1.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (4.11.0)\n",
      "Collecting modin<0.32.0,>=0.31.0 (from awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading modin-0.31.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler[modin,ray]->-r requirements.txt (line 2)) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.26.20)\n",
      "Requirement already satisfied: fsspec>=2022.11.0 in /opt/conda/lib/python3.10/site-packages (from modin<0.32.0,>=0.31.0->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2024.5.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from modin<0.32.0,>=0.31.0->awswrangler[modin,ray]->-r requirements.txt (line 2)) (5.9.8)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=1.2.0->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=1.2.0->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2024.1)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray->-r requirements.txt (line 1))\n",
      "Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (6.0.1)\n",
      "Collecting aiosignal (from ray->-r requirements.txt (line 1))\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting frozenlist (from ray->-r requirements.txt (line 1))\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (2.32.2)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.20.32 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.34.114)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.23.32 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.34.114)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (16.1.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (4.11.0)\n",
      "Collecting modin<0.32.0,>=0.31.0 (from awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading modin-0.31.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler[modin,ray]->-r requirements.txt (line 2)) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.26.20)\n",
      "Requirement already satisfied: fsspec>=2022.11.0 in /opt/conda/lib/python3.10/site-packages (from modin<0.32.0,>=0.31.0->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2024.5.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from modin<0.32.0,>=0.31.0->awswrangler[modin,ray]->-r requirements.txt (line 2)) (5.9.8)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=1.2.0->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=1.2.0->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2024.1)\n",
      "Collecting aiohttp>=3.7 (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting aiohttp-cors (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting colorful (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting py-spy>=0.2.0 (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
      "Collecting opencensus (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /opt/conda/lib/python3.10/site-packages (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.7.2)\n",
      "Collecting prometheus-client>=0.7.1 (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: smart-open in /opt/conda/lib/python3.10/site-packages (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (5.2.1)\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading virtualenv-20.26.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting frozenlist (from ray->-r requirements.txt (line 1))\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray->-r requirements.txt (line 1)) (2.32.2)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.20.32 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.34.114)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.23.32 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.34.114)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (16.1.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from awswrangler[modin,ray]->-r requirements.txt (line 2)) (4.11.0)\n",
      "Collecting modin<0.32.0,>=0.31.0 (from awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading modin-0.31.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler[modin,ray]->-r requirements.txt (line 2)) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.26.20)\n",
      "Requirement already satisfied: fsspec>=2022.11.0 in /opt/conda/lib/python3.10/site-packages (from modin<0.32.0,>=0.31.0->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2024.5.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from modin<0.32.0,>=0.31.0->awswrangler[modin,ray]->-r requirements.txt (line 2)) (5.9.8)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=1.2.0->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=1.2.0->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2024.1)\n",
      "Collecting aiohttp>=3.7 (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting aiohttp-cors (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting colorful (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting py-spy>=0.2.0 (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
      "Collecting opencensus (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /opt/conda/lib/python3.10/site-packages (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.7.2)\n",
      "Collecting prometheus-client>=0.7.1 (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: smart-open in /opt/conda/lib/python3.10/site-packages (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (5.2.1)\n",
      "Collecting aiohttp>=3.7 (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting aiohttp-cors (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting colorful (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting py-spy>=0.2.0 (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
      "Collecting opencensus (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /opt/conda/lib/python3.10/site-packages (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.7.2)\n",
      "Collecting prometheus-client>=0.7.1 (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: smart-open in /opt/conda/lib/python3.10/site-packages (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (5.2.1)\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading virtualenv-20.26.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting grpcio>=1.42.0 (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading grpcio-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting memray (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading memray-1.14.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray->-r requirements.txt (line 1)) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray->-r requirements.txt (line 1)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray->-r requirements.txt (line 1)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray->-r requirements.txt (line 1)) (0.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray->-r requirements.txt (line 1)) (2024.8.30)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp>=3.7->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading virtualenv-20.26.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting grpcio>=1.42.0 (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading grpcio-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting memray (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading memray-1.14.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray->-r requirements.txt (line 1)) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray->-r requirements.txt (line 1)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray->-r requirements.txt (line 1)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray->-r requirements.txt (line 1)) (0.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray->-r requirements.txt (line 1)) (2024.8.30)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp>=3.7->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting grpcio>=1.42.0 (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading grpcio-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting memray (from ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading memray-1.14.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray->-r requirements.txt (line 1)) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray->-r requirements.txt (line 1)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray->-r requirements.txt (line 1)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray->-r requirements.txt (line 1)) (0.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray->-r requirements.txt (line 1)) (2024.8.30)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp>=3.7->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.7->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp>=3.7->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading yarl-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.2/48.2 kB 7.0 MB/s eta 0:00:00\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp>=3.7->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in /opt/conda/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.23.32->awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.16.0)\n",
      "\n",
      "2024-09-11 18:24:32 Downloading - Downloading the training image\n",
      "2024-09-11 18:24:32 Training - Training image download completed. Training in progress.Collecting multidict<7.0,>=4.5 (from aiohttp>=3.7->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp>=3.7->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading yarl-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.2/48.2 kB 12.3 MB/s eta 0:00:00\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp>=3.7->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in /opt/conda/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.23.32->awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.16.0)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (4.1.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/conda/lib/python3.10/site-packages (from memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (3.1.4)\n",
      "Requirement already satisfied: rich>=11.2.0 in /opt/conda/lib/python3.10/site-packages (from memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (13.7.1)\n",
      "Collecting textual>=0.41.0 (from memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading textual-0.79.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading google_api_core-2.19.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.7->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp>=3.7->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading yarl-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.2/48.2 kB 7.8 MB/s eta 0:00:00\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp>=3.7->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in /opt/conda/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.23.32->awswrangler[modin,ray]->-r requirements.txt (line 2)) (1.16.0)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (4.1.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/conda/lib/python3.10/site-packages (from memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (3.1.4)\n",
      "Requirement already satisfied: rich>=11.2.0 in /opt/conda/lib/python3.10/site-packages (from memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (13.7.1)\n",
      "Collecting textual>=0.41.0 (from memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading textual-0.79.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading google_api_core-2.19.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (4.1.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/conda/lib/python3.10/site-packages (from memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (3.1.4)\n",
      "Requirement already satisfied: rich>=11.2.0 in /opt/conda/lib/python3.10/site-packages (from memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (13.7.1)\n",
      "Collecting textual>=0.41.0 (from memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading textual-0.79.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading google_api_core-2.19.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.9->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.2.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.2.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.18.0)\n",
      "Collecting platformdirs<5,>=3.9.1 (from virtualenv!=20.21.1,>=20.0.24->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading platformdirs-4.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (4.7.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.2.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (0.1.2)\n",
      "Collecting mdit-py-plugins (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading mdit_py_plugins-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (0.6.0)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.9->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.2.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.2.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.18.0)\n",
      "Collecting platformdirs<5,>=3.9.1 (from virtualenv!=20.21.1,>=20.0.24->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading platformdirs-4.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (4.7.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.2.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (0.1.2)\n",
      "Collecting mdit-py-plugins (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading mdit_py_plugins-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (0.6.0)\n",
      "Downloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl (65.0 MB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.9->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.2.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.2.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (2.18.0)\n",
      "Collecting platformdirs<5,>=3.9.1 (from virtualenv!=20.21.1,>=20.0.24->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading platformdirs-4.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (4.7.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.2.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (0.1.2)\n",
      "Collecting mdit-py-plugins (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading mdit_py_plugins-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2))\n",
      "Downloading uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,default]<3.0.0,>=2.30.0; extra == \"ray\"->awswrangler[modin,ray]->-r requirements.txt (line 2)) (0.6.0)\n",
      "Downloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl (65.0 MB)\n",
      "Downloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl (65.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.0/65.0 MB 52.4 MB/s eta 0:00:00\n",
      "Downloading modin-0.31.0-py3-none-any.whl (1.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 105.9 MB/s eta 0:00:00\n",
      "Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 378.0/378.0 kB 71.6 MB/s eta 0:00:00\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 239.5/239.5 kB 57.2 MB/s eta 0:00:00\n",
      "Downloading awswrangler-3.9.1-py3-none-any.whl (381 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 381.7/381.7 kB 74.7 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 128.2 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 151.1 MB/s eta 0:00:00\n",
      "Downloading prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 kB 16.7 MB/s eta 0:00:00\n",
      "Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 127.1 MB/s eta 0:00:00\n",
      "Downloading virtualenv-20.26.4-py3-none-any.whl (6.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 148.1 MB/s eta 0:00:00\n",
      "Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 201.4/201.4 kB 50.4 MB/s eta 0:00:00\n",
      "Downloading memray-1.14.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.3/8.3 MB 135.9 MB/s eta 0:00:00\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.2/128.2 kB 34.9 MB/s eta 0:00:00\n",
      "Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 468.9/468.9 kB 86.7 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.19.2-py3-none-any.whl (139 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.4/139.4 kB 35.8 MB/s eta 0:00:00\n",
      "Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.6/124.6 kB 33.0 MB/s eta 0:00:00\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading textual-0.79.1-py3-none-any.whl (581 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 581.6/581.6 kB 89.7 MB/s eta 0:00:00\n",
      "Downloading platformdirs-4.3.2-py3-none-any.whl (18 kB)\n",
      "Downloading yarl-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 446.8/446.8 kB 77.5 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.9/200.9 kB 47.7 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 220.9/220.9 kB 49.6 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.1/50.1 kB 12.8 MB/s eta 0:00:00\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.5/181.5 kB 46.0 MB/s eta 0:00:00\n",
      "Downloading mdit_py_plugins-0.4.2-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.3/55.3 kB 15.9 MB/s eta 0:00:00\n",
      "Downloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.0/65.0 MB 44.7 MB/s eta 0:00:00\n",
      "Downloading modin-0.31.0-py3-none-any.whl (1.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 95.2 MB/s eta 0:00:00\n",
      "Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 378.0/378.0 kB 60.1 MB/s eta 0:00:00\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 239.5/239.5 kB 51.7 MB/s eta 0:00:00\n",
      "Downloading awswrangler-3.9.1-py3-none-any.whl (381 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 381.7/381.7 kB 58.6 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 105.5 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 123.4 MB/s eta 0:00:00\n",
      "Downloading prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 kB 14.9 MB/s eta 0:00:00\n",
      "Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 120.6 MB/s eta 0:00:00\n",
      "Downloading virtualenv-20.26.4-py3-none-any.whl (6.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 123.9 MB/s eta 0:00:00\n",
      "Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 201.4/201.4 kB 43.8 MB/s eta 0:00:00\n",
      "Downloading memray-1.14.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.3/8.3 MB 131.3 MB/s eta 0:00:00\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.2/128.2 kB 31.2 MB/s eta 0:00:00\n",
      "Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 468.9/468.9 kB 73.7 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.19.2-py3-none-any.whl (139 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.4/139.4 kB 35.7 MB/s eta 0:00:00\n",
      "Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.6/124.6 kB 32.0 MB/s eta 0:00:00\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading textual-0.79.1-py3-none-any.whl (581 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 581.6/581.6 kB 81.0 MB/s eta 0:00:00\n",
      "Downloading platformdirs-4.3.2-py3-none-any.whl (18 kB)\n",
      "Downloading yarl-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 446.8/446.8 kB 74.5 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.9/200.9 kB 38.2 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 220.9/220.9 kB 46.3 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.1/50.1 kB 12.6 MB/s eta 0:00:00\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.5/181.5 kB 41.2 MB/s eta 0:00:00\n",
      "Downloading mdit_py_plugins-0.4.2-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.3/55.3 kB 14.9 MB/s eta 0:00:00\n",
      "Downloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.0/65.0 MB 31.5 MB/s eta 0:00:00\n",
      "Downloading modin-0.31.0-py3-none-any.whl (1.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 68.1 MB/s eta 0:00:00\n",
      "Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 378.0/378.0 kB 42.8 MB/s eta 0:00:00\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 239.5/239.5 kB 27.8 MB/s eta 0:00:00\n",
      "Downloading awswrangler-3.9.1-py3-none-any.whl (381 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 381.7/381.7 kB 38.5 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 80.7 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 91.2 MB/s eta 0:00:00\n",
      "Downloading prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 kB 9.9 MB/s eta 0:00:00\n",
      "Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 94.1 MB/s eta 0:00:00\n",
      "Downloading virtualenv-20.26.4-py3-none-any.whl (6.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 106.5 MB/s eta 0:00:00\n",
      "Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 201.4/201.4 kB 28.2 MB/s eta 0:00:00\n",
      "Downloading memray-1.14.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.3/8.3 MB 106.4 MB/s eta 0:00:00\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.2/128.2 kB 18.3 MB/s eta 0:00:00\n",
      "Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 468.9/468.9 kB 50.5 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.19.2-py3-none-any.whl (139 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.4/139.4 kB 17.7 MB/s eta 0:00:00\n",
      "Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.6/124.6 kB 18.7 MB/s eta 0:00:00\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading textual-0.79.1-py3-none-any.whl (581 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 581.6/581.6 kB 52.2 MB/s eta 0:00:00\n",
      "Downloading platformdirs-4.3.2-py3-none-any.whl (18 kB)\n",
      "Downloading yarl-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 446.8/446.8 kB 45.6 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.9/200.9 kB 27.1 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 220.9/220.9 kB 29.3 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.1/50.1 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.5/181.5 kB 23.8 MB/s eta 0:00:00\n",
      "Downloading mdit_py_plugins-0.4.2-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.3/55.3 kB 7.3 MB/s eta 0:00:00\n",
      "Downloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: py-spy, opencensus-context, distlib, colorful, uc-micro-py, pyasn1-modules, proto-plus, prometheus-client, platformdirs, multidict, msgpack, grpcio, googleapis-common-protos, frozenlist, cachetools, async-timeout, aiohappyeyeballs, yarl, virtualenv, mdit-py-plugins, linkify-it-py, google-auth, aiosignal, modin, google-api-core, aiohttp, textual, ray, opencensus, aiohttp-cors, memray, awswrangler\n",
      "Installing collected packages: py-spy, opencensus-context, distlib, colorful, uc-micro-py, pyasn1-modules, proto-plus, prometheus-client, platformdirs, multidict, msgpack, grpcio, googleapis-common-protos, frozenlist, cachetools, async-timeout, aiohappyeyeballs, yarl, virtualenv, mdit-py-plugins, linkify-it-py, google-auth, aiosignal, modin, google-api-core, aiohttp, textual, ray, opencensus, aiohttp-cors, memray, awswrangler\n",
      "Attempting uninstall: platformdirs\n",
      "Found existing installation: platformdirs 4.1.0\n",
      "Uninstalling platformdirs-4.1.0:\n",
      "Successfully uninstalled platformdirs-4.1.0\n",
      "Installing collected packages: py-spy, opencensus-context, distlib, colorful, uc-micro-py, pyasn1-modules, proto-plus, prometheus-client, platformdirs, multidict, msgpack, grpcio, googleapis-common-protos, frozenlist, cachetools, async-timeout, aiohappyeyeballs, yarl, virtualenv, mdit-py-plugins, linkify-it-py, google-auth, aiosignal, modin, google-api-core, aiohttp, textual, ray, opencensus, aiohttp-cors, memray, awswrangler\n",
      "Attempting uninstall: platformdirs\n",
      "Found existing installation: platformdirs 4.1.0\n",
      "Uninstalling platformdirs-4.1.0:\n",
      "Successfully uninstalled platformdirs-4.1.0\n",
      "Attempting uninstall: platformdirs\n",
      "Found existing installation: platformdirs 4.1.0\n",
      "Uninstalling platformdirs-4.1.0:\n",
      "Successfully uninstalled platformdirs-4.1.0\n",
      "Successfully installed aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiohttp-cors-0.7.0 aiosignal-1.3.1 async-timeout-4.0.3 awswrangler-3.9.1 cachetools-5.5.0 colorful-0.5.6 distlib-0.3.8 frozenlist-1.4.1 google-api-core-2.19.2 google-auth-2.34.0 googleapis-common-protos-1.65.0 grpcio-1.66.1 linkify-it-py-2.0.3 mdit-py-plugins-0.4.2 memray-1.14.0 modin-0.31.0 msgpack-1.1.0 multidict-6.1.0 opencensus-0.11.4 opencensus-context-0.1.3 platformdirs-4.3.2 prometheus-client-0.20.0 proto-plus-1.24.0 py-spy-0.3.14 pyasn1-modules-0.4.1 ray-2.35.0 textual-0.79.1 uc-micro-py-1.0.3 virtualenv-20.26.4 yarl-1.11.1\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Successfully installed aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiohttp-cors-0.7.0 aiosignal-1.3.1 async-timeout-4.0.3 awswrangler-3.9.1 cachetools-5.5.0 colorful-0.5.6 distlib-0.3.8 frozenlist-1.4.1 google-api-core-2.19.2 google-auth-2.34.0 googleapis-common-protos-1.65.0 grpcio-1.66.1 linkify-it-py-2.0.3 mdit-py-plugins-0.4.2 memray-1.14.0 modin-0.31.0 msgpack-1.1.0 multidict-6.1.0 opencensus-0.11.4 opencensus-context-0.1.3 platformdirs-4.3.2 prometheus-client-0.20.0 proto-plus-1.24.0 py-spy-0.3.14 pyasn1-modules-0.4.1 ray-2.35.0 textual-0.79.1 uc-micro-py-1.0.3 virtualenv-20.26.4 yarl-1.11.1\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2024-09-11 18:24:48,281 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-09-11 18:24:48,281 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-09-11 18:24:48,282 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-09-11 18:24:48,283 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-09-11 18:24:48,294 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-09-11 18:24:48,295 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-09-11 18:24:48,306 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-09-11 18:24:48,307 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-09-11 18:24:48,318 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-3\",\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"input_data_location\": \"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\",\n",
      "        \"output_data_location\": \"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-3\",\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"pytorch-training-2024-09-11-18-24-14-866\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-09-11-18-24-14-866/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"compute_aggregations\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-3\",\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"compute_aggregations.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"input_data_location\":\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\",\"output_data_location\":\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\"}\n",
      "SM_USER_ENTRY_POINT=compute_aggregations.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"instance_groups\":[{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[]\n",
      "SM_CURRENT_HOST=algo-2\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.m5.xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-3\",\"algo-1\",\"algo-2\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=compute_aggregations\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=0\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-09-11-18-24-14-866/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.m5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"input_data_location\":\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\",\"output_data_location\":\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"pytorch-training-2024-09-11-18-24-14-866\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-09-11-18-24-14-866/source/sourcedir.tar.gz\",\"module_name\":\"compute_aggregations\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"instance_groups\":[{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"compute_aggregations.py\"}\n",
      "SM_USER_ARGS=[\"--input_data_location\",\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\",\"--output_data_location\",\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_HP_INPUT_DATA_LOCATION=s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\n",
      "SM_HP_OUTPUT_DATA_LOCATION=s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.10 compute_aggregations.py --input_data_location s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv --output_data_location s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\n",
      "2024-09-11 18:24:48,319 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
      "2024-09-11 18:24:48,319 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "2024-09-11 18:24:48,378 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-09-11 18:24:48,378 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-09-11 18:24:48,380 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-09-11 18:24:48,380 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-09-11 18:24:48,391 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-09-11 18:24:48,392 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-09-11 18:24:48,403 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-09-11 18:24:48,404 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-09-11 18:24:48,414 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-3\",\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"input_data_location\": \"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\",\n",
      "        \"output_data_location\": \"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-3\",\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"pytorch-training-2024-09-11-18-24-14-866\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-09-11-18-24-14-866/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"compute_aggregations\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-3\",\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"compute_aggregations.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"input_data_location\":\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\",\"output_data_location\":\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\"}\n",
      "SM_USER_ENTRY_POINT=compute_aggregations.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"instance_groups\":[{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.m5.xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-3\",\"algo-1\",\"algo-2\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=compute_aggregations\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=0\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-09-11-18-24-14-866/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.m5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"input_data_location\":\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\",\"output_data_location\":\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"pytorch-training-2024-09-11-18-24-14-866\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-09-11-18-24-14-866/source/sourcedir.tar.gz\",\"module_name\":\"compute_aggregations\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"instance_groups\":[{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"compute_aggregations.py\"}\n",
      "SM_USER_ARGS=[\"--input_data_location\",\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\",\"--output_data_location\",\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_HP_INPUT_DATA_LOCATION=s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\n",
      "SM_HP_OUTPUT_DATA_LOCATION=s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.10 compute_aggregations.py --input_data_location s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv --output_data_location s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\n",
      "2024-09-11 18:24:48,416 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
      "2024-09-11 18:24:48,416 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "Successfully installed aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiohttp-cors-0.7.0 aiosignal-1.3.1 async-timeout-4.0.3 awswrangler-3.9.1 cachetools-5.5.0 colorful-0.5.6 distlib-0.3.8 frozenlist-1.4.1 google-api-core-2.19.2 google-auth-2.34.0 googleapis-common-protos-1.65.0 grpcio-1.66.1 linkify-it-py-2.0.3 mdit-py-plugins-0.4.2 memray-1.14.0 modin-0.31.0 msgpack-1.1.0 multidict-6.1.0 opencensus-0.11.4 opencensus-context-0.1.3 platformdirs-4.3.2 prometheus-client-0.20.0 proto-plus-1.24.0 py-spy-0.3.14 pyasn1-modules-0.4.1 ray-2.35.0 textual-0.79.1 uc-micro-py-1.0.3 virtualenv-20.26.4 yarl-1.11.1\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2024-09-11 18:24:49,436 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-09-11 18:24:49,436 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-09-11 18:24:49,438 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-09-11 18:24:49,438 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-09-11 18:24:49,450 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-09-11 18:24:49,450 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-09-11 18:24:49,462 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-09-11 18:24:49,463 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-09-11 18:24:49,473 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-3\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-3\",\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"input_data_location\": \"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\",\n",
      "        \"output_data_location\": \"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-3\",\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"pytorch-training-2024-09-11-18-24-14-866\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-09-11-18-24-14-866/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"compute_aggregations\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-3\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-3\",\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"compute_aggregations.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"input_data_location\":\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\",\"output_data_location\":\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\"}\n",
      "SM_USER_ENTRY_POINT=compute_aggregations.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-3\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"instance_groups\":[{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[]\n",
      "SM_CURRENT_HOST=algo-3\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.m5.xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-3\",\"algo-1\",\"algo-2\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=compute_aggregations\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=0\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-09-11-18-24-14-866/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-3\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.m5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"input_data_location\":\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\",\"output_data_location\":\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"pytorch-training-2024-09-11-18-24-14-866\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-152804913371/pytorch-training-2024-09-11-18-24-14-866/source/sourcedir.tar.gz\",\"module_name\":\"compute_aggregations\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-3\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"instance_groups\":[{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"compute_aggregations.py\"}\n",
      "SM_USER_ARGS=[\"--input_data_location\",\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\",\"--output_data_location\",\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_HP_INPUT_DATA_LOCATION=s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\n",
      "SM_HP_OUTPUT_DATA_LOCATION=s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.10 compute_aggregations.py --input_data_location s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv --output_data_location s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output\n",
      "2024-09-11 18:24:49,475 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
      "2024-09-11 18:24:49,475 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "2024-09-11 18:24:50,119#011INFO usage_lib.py:467 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\n",
      "2024-09-11 18:24:50,120#011INFO scripts.py:767 -- #033[37mLocal node IP#033[39m: #033[1m10.2.244.87#033[22m\n",
      "2024-09-11 18:24:51,412#011SUCC scripts.py:804 -- #033[32m--------------------#033[39m\n",
      "2024-09-11 18:24:51,413#011SUCC scripts.py:805 -- #033[32mRay runtime started.#033[39m\n",
      "2024-09-11 18:24:51,413#011SUCC scripts.py:806 -- #033[32m--------------------#033[39m\n",
      "2024-09-11 18:24:51,413#011INFO scripts.py:808 -- #033[36mNext steps#033[39m\n",
      "2024-09-11 18:24:51,413#011INFO scripts.py:811 -- To add another node to this Ray cluster, run\n",
      "2024-09-11 18:24:51,413#011INFO scripts.py:814 -- #033[1m  ray start --address='10.2.244.87:9339'#033[22m\n",
      "2024-09-11 18:24:51,413#011INFO scripts.py:823 -- To connect to this Ray cluster:\n",
      "2024-09-11 18:24:51,413#011INFO scripts.py:825 -- #033[35mimport#033[39m#033[26m ray\n",
      "2024-09-11 18:24:51,413#011INFO scripts.py:826 -- ray#033[35m.#033[39m#033[26minit()\n",
      "2024-09-11 18:24:51,414#011INFO scripts.py:857 -- To terminate the Ray runtime, run\n",
      "2024-09-11 18:24:51,414#011INFO scripts.py:858 -- #033[1m  ray stop#033[22m\n",
      "2024-09-11 18:24:51,414#011INFO scripts.py:861 -- To view the status of the cluster, use\n",
      "2024-09-11 18:24:51,414#011INFO scripts.py:862 --   #033[1mray status#033[22m#033[26m\n",
      "2024-09-11 18:24:51,617#011INFO worker.py:1598 -- Connecting to existing Ray cluster at address: 10.2.244.87:9339...\n",
      "2024-09-11 18:24:51,632#011INFO worker.py:1783 -- Connected to Ray cluster.\n",
      "Waiting 60 seconds for 3 nodes to join\n",
      "1 nodes connected to cluster\n",
      "1 nodes connected to cluster\n",
      "[2024-09-11 18:25:00,071 W 81 81] global_state_accessor.cc:459: Retrying to get node with node ID ee6087ce82b970c2161adc27eb5e2e8a71e4343c2c2b65d1e1ad465b\n",
      "[2024-09-11 18:25:01,310 W 81 81] global_state_accessor.cc:459: Retrying to get node with node ID 788172fa8e139826d6c7fd87b5cd7b7edb8c45f26d90969a287ccc09\n",
      "All workers present and accounted for\n",
      "{'memory': 27187935644.0, 'CPU': 12.0, 'node:10.2.247.41': 1.0, 'object_store_memory': 12229547211.0, 'node:10.2.245.152': 1.0, 'node:__internal_head__': 1.0, 'node:10.2.244.87': 1.0}\n",
      "2024-09-11 18:25:02,676#011WARNING file_meta_provider.py:211 -- Skipping expansion of 1 path(s). If your paths contain directories or if file size collection is required, try rerunning this read with `meta_provider=DefaultFileMetadataProvider()`.\n",
      "2024-09-11 18:25:04,478#011INFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-09-11_18-24-50_120712_81/logs/ray-data\n",
      "2024-09-11 18:25:04,478#011INFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadArrowCSV]\n",
      "Running 0: 0.00 row [00:00, ? row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24) 1: 0.00 row [00:00, ? row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 256.0MB]: : 0.00 row [00:01, ? row/s]#033[A\n",
      "#015- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 256.0MB]: : 0.00 row [00:01, ? row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 256.0MB/5.7GB object_store_memory: : 0.00 row [00:01, ? row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 256.0MB/5.7GB object_store_memory: : 0.00 row [00:01, ? row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 256.0MB]: : 0.00 row [00:02, ? row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 256.0MB/5.7GB object_store_memory: : 0.00 row [00:02, ? row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 256.0MB]: : 0.00 row [00:03, ? row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 256.0MB/5.7GB object_store_memory: : 0.00 row [00:03, ? row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 256.0MB]: : 0.00 row [00:04, ? row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 256.0MB/5.7GB object_store_memory: : 0.00 row [00:04, ? row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 256.0MB]: : 0.00 row [00:05, ? row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 256.0MB/5.7GB object_store_memory: : 0.00 row [00:05, ? row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.7MB]: : 0.00 row [00:06, ? row/s] #033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.7MB]: : 523k row [00:06, 86.4k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.7MB]: : 523k row [00:06, 86.4k row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.7MB/5.7GB object_store_memory: : 0.00 row [00:06, ? row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.7MB/5.7GB object_store_memory: : 523k row [00:06, 86.3k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.7MB/5.7GB object_store_memory: : 523k row [00:06, 86.3k row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.7MB]: : 523k row [00:07, 86.4k row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.7MB/5.7GB object_store_memory: : 523k row [00:07, 86.3k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.7MB/5.7GB object_store_memory: : 1.04M row [00:08, 141k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.7MB/5.7GB object_store_memory: : 1.04M row [00:08, 141k row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.7MB]: : 1.04M row [00:08, 141k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.7MB]: : 1.04M row [00:08, 141k row/s]\n",
      "#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.7MB]: : 1.04M row [00:09, 141k row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.7MB/5.7GB object_store_memory: : 1.04M row [00:09, 141k row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.7MB]: : 1.04M row [00:10, 141k row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.7MB/5.7GB object_store_memory: : 1.04M row [00:10, 141k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 16.2MB/5.7GB object_store_memory: : 1.04M row [00:11, 141k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 16.2MB/5.7GB object_store_memory: : 1.57M row [00:11, 154k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 16.2MB/5.7GB object_store_memory: : 1.57M row [00:11, 154k row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.8MB]: : 1.04M row [00:11, 141k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.8MB]: : 1.57M row [00:11, 152k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.8MB]: : 1.57M row [00:11, 152k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.8MB]: : 1.57M row [00:12, 152k row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.8MB/5.7GB object_store_memory: : 1.57M row [00:12, 154k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.8MB/5.7GB object_store_memory: : 1.57M row [00:12, 154k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.8MB/5.7GB object_store_memory: : 2.09M row [00:13, 179k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.8MB/5.7GB object_store_memory: : 2.09M row [00:13, 179k row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.8MB]: : 2.09M row [00:13, 180k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.8MB]: : 2.09M row [00:13, 180k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.8MB]: : 2.09M row [00:14, 180k row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.8MB/5.7GB object_store_memory: : 2.09M row [00:14, 179k row/s]\n",
      "✔️  Dataset execution finished in 14.87 seconds: : 2.09M row [00:14, 179k row/s]\n",
      "✔️  Dataset execution finished in 14.87 seconds:  83%|████████▎ | 2.09M/2.52M [00:14<00:02, 179k row/s]\n",
      "✔️  Dataset execution finished in 14.87 seconds: 100%|██████████| 2.52M/2.52M [00:14<00:00, 203k row/s]#015✔️  Dataset execution finished in 14.87 seconds: 100%|██████████| 2.52M/2.52M [00:14<00:00, 203k row/s]\n",
      "#033[A\n",
      "✔️  Dataset execution finished in 14.87 seconds: 100%|██████████| 2.52M/2.52M [00:14<00:00, 170k row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.8MB]: : 2.09M row [00:14, 180k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 0 active, 0 queued, [cpu: 0.0, objects: 4.5MB]: : 2.09M row [00:14, 180k row/s] #033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 0 active, 0 queued, [cpu: 0.0, objects: 4.5MB]: : 2.52M row [00:14, 203k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 0 active, 0 queued, [cpu: 0.0, objects: 4.5MB]: : 2.52M row [00:14, 203k row/s]#033[A\n",
      "#015                                                                                                                #015#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 0 active, 0 queued, [cpu: 0.0, objects: 4.5MB]: : 2.52M row [00:14, 170k row/s]\n",
      "2024-09-11 18:25:19,365#011INFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-09-11_18-24-50_120712_81/logs/ray-data\n",
      "2024-09-11 18:25:19,365#011INFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadArrowCSV]\n",
      "Running 0: 0.00 row [00:00, ? row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24) 1: 0.00 row [00:00, ? row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 256.0MB]: : 0.00 row [00:01, ? row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 256.0MB]: : 0.00 row [00:01, ? row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 256.0MB/5.7GB object_store_memory: : 0.00 row [00:01, ? row/s]#015Running: 1/12 CPU, 0/0 GPU, 256.0MB/5.7GB object_store_memory: : 0.00 row [00:01, ? row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 256.0MB]: : 0.00 row [00:02, ? row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 256.0MB/5.7GB object_store_memory: : 0.00 row [00:02, ? row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 16.1MB/5.7GB object_store_memory: : 0.00 row [00:03, ? row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 16.1MB/5.7GB object_store_memory: : 218k row [00:03, 72.0k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 16.1MB/5.7GB object_store_memory: : 218k row [00:03, 72.0k row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 16.1MB]: : 0.00 row [00:03, ? row/s] #033[A\n",
      "#015- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 16.1MB]: : 240k row [00:03, 78.9k row/s]#033[A\n",
      "#015- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 16.1MB]: : 240k row [00:03, 78.9k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.7MB]: : 240k row [00:04, 78.9k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.7MB]: : 523k row [00:04, 142k row/s] #033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.7MB]: : 523k row [00:04, 142k row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.7MB/5.7GB object_store_memory: : 218k row [00:04, 72.0k row/s]#015Running: 1/12 CPU, 0/0 GPU, 10.7MB/5.7GB object_store_memory: : 523k row [00:04, 144k row/s] #015Running: 1/12 CPU, 0/0 GPU, 10.7MB/5.7GB object_store_memory: : 523k row [00:04, 144k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 16.1MB/5.7GB object_store_memory: : 523k row [00:05, 144k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 16.1MB/5.7GB object_store_memory: : 631k row [00:05, 133k row/s]#015Running: 1/12 CPU, 0/0 GPU, 16.1MB/5.7GB object_store_memory: : 631k row [00:05, 133k row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 16.1MB]: : 523k row [00:05, 142k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 16.1MB]: : 653k row [00:05, 138k row/s]\n",
      "#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 16.1MB]: : 653k row [00:05, 138k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.7MB]: : 653k row [00:06, 138k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.7MB]: : 1.04M row [00:06, 213k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.7MB]: : 1.04M row [00:06, 213k row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.7MB/5.7GB object_store_memory: : 631k row [00:06, 133k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.7MB/5.7GB object_store_memory: : 1.04M row [00:06, 216k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.7MB/5.7GB object_store_memory: : 1.04M row [00:06, 216k row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.8MB]: : 1.04M row [00:07, 213k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.8MB]: : 1.57M row [00:07, 306k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.8MB]: : 1.57M row [00:07, 306k row/s]#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.8MB/5.7GB object_store_memory: : 1.04M row [00:07, 216k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.8MB/5.7GB object_store_memory: : 1.57M row [00:07, 308k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.8MB/5.7GB object_store_memory: : 1.57M row [00:07, 308k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.8MB/5.7GB object_store_memory: : 2.09M row [00:08, 368k row/s]\n",
      "Running: 1/12 CPU, 0/0 GPU, 10.8MB/5.7GB object_store_memory: : 2.09M row [00:08, 368k row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.8MB]: : 2.09M row [00:08, 366k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.8MB]: : 2.09M row [00:08, 366k row/s]#033[A\n",
      "✔️  Dataset execution finished in 9.15 seconds: : 2.09M row [00:09, 368k row/s]\n",
      "✔️  Dataset execution finished in 9.15 seconds: : 2.52M row [00:09, 391k row/s]\n",
      "✔️  Dataset execution finished in 9.15 seconds: : 2.52M row [00:09, 391k row/s]\n",
      "#033[A\n",
      "✔️  Dataset execution finished in 9.15 seconds: : 2.52M row [00:09, 276k row/s]\n",
      "- ReadArrowCSV->SplitBlocks(24): 1 active, 0 queued, [cpu: 1.0, objects: 10.8MB]: : 2.09M row [00:09, 366k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 0 active, 0 queued, [cpu: 0.0, objects: 0.0B]: : 2.09M row [00:09, 366k row/s]  #033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 0 active, 0 queued, [cpu: 0.0, objects: 0.0B]: : 2.52M row [00:09, 390k row/s]#033[A\n",
      "- ReadArrowCSV->SplitBlocks(24): 0 active, 0 queued, [cpu: 0.0, objects: 0.0B]: : 2.52M row [00:09, 390k row/s]#033[A\n",
      "#015                                                                                                               #015#033[A#015- ReadArrowCSV->SplitBlocks(24): 0 active, 0 queued, [cpu: 0.0, objects: 0.0B]: : 2.52M row [00:09, 276k row/s]\n",
      "########################################### File read from S3 in: 26.10167076099998s ###########################################\n",
      "#033[36m(_remote_exec_multi_chain pid=189, ip=10.2.245.152)#033[0m FutureWarning: The 'axis' keyword in DataFrame.groupby is deprecated and will be removed in a future version.\n",
      "########################################### Account aggregation completed in: 4.486113913999986s ###########################################\n",
      "UserWarning: <function GroupBy.<lambda>> is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "Please refer to https://modin.readthedocs.io/en/stable/supported_apis/defaulting_to_pandas.html for explanation.\n",
      "########################################### Monthly balance aggregation completed in: 33.81555653999999s ###########################################\n",
      "2024-09-11 18:26:07,185#011INFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-09-11_18-24-50_120712_81/logs/ray-data\n",
      "2024-09-11 18:26:07,185#011INFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> AllToAllOperator[Repartition] -> TaskPoolMapOperator[Write]\n",
      "Running 0: 0.00 row [00:00, ? row/s]\n",
      "- Repartition 1: 0.00 row [00:00, ? row/s]#033[A\n",
      "Split Repartition 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]#033[A#033[A\n",
      "- Write 3: 0.00 row [00:00, ? row/s]#033[A#033[A#033[A\n",
      "✔️  Dataset execution finished in 0.81 seconds: : 0.00 row [00:00, ? row/s]\n",
      "✔️  Dataset execution finished in 0.81 seconds: : 1.00 row [00:00, 1.23 row/s]\n",
      "✔️  Dataset execution finished in 0.81 seconds: : 1.00 row [00:00, 1.23 row/s]#015                                                                              #015\n",
      "#015                                          #015#033[A\n",
      "#015                                                                  #015#033[A#033[A\n",
      "#015                                    #015#033[A#033[A#033[A\n",
      "✔️  Dataset execution finished in 0.81 seconds: : 1.00 row [00:00, 1.23 row/s]\n",
      "#015- Repartition 1: 0.00 row [00:00, ? row/s]#033[A\n",
      "Split Repartition 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]#033[A#033[A\n",
      "#015- Write 3: 0.00 row [00:00, ? row/s]#033[A#033[A#033[A\n",
      "- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 0.0B], 125719 rows output: : 0.00 row [00:00, ? row/s]#033[A\n",
      "- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 0.0B], 125719 rows output:   0%|          | 0.00/126k [00:00<?, ? row/s]#033[A\n",
      "- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 0.0B], 125719 rows output: 100%|██████████| 126k/126k [00:00<00:00, 155k row/s]#033[A\n",
      "- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 0.0B], 125719 rows output: 100%|██████████| 126k/126k [00:00<00:00, 155k row/s]#033[A\n",
      "#033[A\n",
      "#015                                                                  #015#033[A#033[A\n",
      "#033[A#033[A#033[A\n",
      "- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 0.0B], 125719 rows output: 100%|██████████| 126k/126k [00:00<00:00, 155k row/s]\n",
      "Split Repartition 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]#033[A#033[A\n",
      "- Write 3: 0.00 row [00:00, ? row/s]#033[A#033[A#033[A\n",
      "*- Split Repartition:   0%|          | 0.00/1.00 [00:00<?, ? row/s]#033[A#033[A\n",
      "*- Split Repartition:   0%|          | 0.00/126k [00:00<?, ? row/s]#033[A#033[A\n",
      "*- Split Repartition: 100%|██████████| 126k/126k [00:00<00:00, 155k row/s]#033[A#033[A\n",
      "*- Split Repartition: 100%|██████████| 126k/126k [00:00<00:00, 155k row/s]#033[A#033[A\n",
      "#015                                                                            #015#033[A#033[A\n",
      "#033[A#033[A#033[A\n",
      "*- Split Repartition: 100%|██████████| 126k/126k [00:00<00:00, 155k row/s]\n",
      "- Write 3: 0.00 row [00:00, ? row/s]#033[A#033[A#033[A\n",
      "- Write: 0 active, 0 queued, [cpu: 0.0, objects: 0.0B]: : 0.00 row [00:00, ? row/s]#033[A#033[A#033[A\n",
      "- Write: 0 active, 0 queued, [cpu: 0.0, objects: 0.0B]: : 1.00 row [00:00, 1.23 row/s]#033[A#033[A#033[A\n",
      "- Write: 0 active, 0 queued, [cpu: 0.0, objects: 0.0B]: : 1.00 row [00:00, 1.23 row/s]#033[A#033[A#033[A\n",
      "#015                                                                                      #015#033[A#033[A#033[A\n",
      "- Write: 0 active, 0 queued, [cpu: 0.0, objects: 0.0B]: : 1.00 row [00:00, 1.23 row/s]\n",
      "2024-09-11 18:26:08,432#011INFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-09-11_18-24-50_120712_81/logs/ray-data\n",
      "2024-09-11 18:26:08,432#011INFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> AllToAllOperator[Repartition] -> TaskPoolMapOperator[Write]\n",
      "Running 0: 0.00 row [00:00, ? row/s]\n",
      "- Repartition 1: 0.00 row [00:00, ? row/s]#033[A\n",
      "Split Repartition 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]#033[A#033[A\n",
      "- Write 3: 0.00 row [00:00, ? row/s]#033[A#033[A#033[A\n",
      "- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 126.1MB], 1380778 rows output: : 0.00 row [00:01, ? row/s]#033[A\n",
      "- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 126.1MB], 1380778 rows output:   0%|          | 0.00/1.38M [00:01<?, ? row/s]#033[A\n",
      "- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 126.1MB], 1380778 rows output: 100%|██████████| 1.38M/1.38M [00:01<00:00, 1.32M row/s]#033[A\n",
      "- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 126.1MB], 1380778 rows output: 100%|██████████| 1.38M/1.38M [00:01<00:00, 1.32M row/s]#033[A\n",
      "- Write: 1 active, 0 queued, [cpu: 1.0, objects: 256.0MB]: : 0.00 row [00:01, ? row/s]#033[A#033[A#033[A\n",
      "- Write: 1 active, 0 queued, [cpu: 1.0, objects: 256.0MB]: : 0.00 row [00:01, ? row/s]#033[A#033[A#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 382.1MB/2.8GB object_store_memory: : 0.00 row [00:01, ? row/s]#015Running: 1/12 CPU, 0/0 GPU, 382.1MB/2.8GB object_store_memory: : 0.00 row [00:01, ? row/s]\n",
      "- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 126.1MB], 1380778 rows output: 100%|██████████| 1.38M/1.38M [00:02<00:00, 1.32M row/s]#033[A\n",
      "- Write: 1 active, 0 queued, [cpu: 1.0, objects: 256.0MB]: : 0.00 row [00:02, ? row/s]#033[A#033[A#033[A\n",
      "Running: 1/12 CPU, 0/0 GPU, 382.1MB/2.8GB object_store_memory: : 0.00 row [00:02, ? row/s]\n",
      "✔️  Dataset execution finished in 2.77 seconds: : 0.00 row [00:02, ? row/s]\n",
      "✔️  Dataset execution finished in 2.77 seconds:   0%|          | 0.00/1.00 [00:02<?, ? row/s]#015✔️  Dataset execution finished in 2.77 seconds: 100%|██████████| 1.00/1.00 [00:02<00:00, 2.77s/ row]#015✔️  Dataset execution finished in 2.77 seconds: 100%|██████████| 1.00/1.00 [00:02<00:00, 2.77s/ row]#015                                                                                                    #015\n",
      "#015                                                                                                                                             #015#033[A\n",
      "#015                                                                  #015#033[A#033[A\n",
      "#015                                                                                      #015#033[A#033[A#033[A\n",
      "✔️  Dataset execution finished in 2.77 seconds: 100%|██████████| 1.00/1.00 [00:02<00:00, 2.77s/ row]\n",
      "#015- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 126.1MB], 1380778 rows output: 100%|██████████| 1.38M/1.38M [00:02<00:00, 1.32M row/s]#033[A\n",
      "#015Split Repartition 2:   0%|          | 0.00/1.00 [00:02<?, ? row/s]#033[A#033[A\n",
      "#015- Write: 1 active, 0 queued, [cpu: 1.0, objects: 256.0MB]: : 0.00 row [00:02, ? row/s]#033[A#033[A#033[A\n",
      "- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 0.0B], 1380778 rows output: 100%|██████████| 1.38M/1.38M [00:02<00:00, 1.32M row/s]   #033[A\n",
      "#015- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 0.0B], 1380778 rows output: 100%|██████████| 1.38M/1.38M [00:02<00:00, 1.32M row/s]#033[A\n",
      "#015                                                                                                                                          #015#033[A\n",
      "#015                                                                  #015#033[A#033[A\n",
      "#015                                                                                      #015#033[A#033[A#033[A\n",
      "- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 0.0B], 1380778 rows output: 100%|██████████| 1.38M/1.38M [00:02<00:00, 498k row/s]\n",
      "Split Repartition 2:   0%|          | 0.00/1.00 [00:02<?, ? row/s]#033[A#033[A\n",
      "- Write: 1 active, 0 queued, [cpu: 1.0, objects: 256.0MB]: : 0.00 row [00:02, ? row/s]#033[A#033[A#033[A\n",
      "*- Split Repartition:   0%|          | 0.00/1.00 [00:02<?, ? row/s]#033[A#033[A\n",
      "*- Split Repartition:   0%|          | 0.00/1.38M [00:02<?, ? row/s]#033[A#033[A\n",
      "*- Split Repartition: 100%|██████████| 1.38M/1.38M [00:02<00:00, 498k row/s]#033[A#033[A\n",
      "*- Split Repartition: 100%|██████████| 1.38M/1.38M [00:02<00:00, 498k row/s]#033[A#033[A\n",
      "#033[A#033[A\n",
      "#033[A#033[A#033[A\n",
      "*- Split Repartition: 100%|██████████| 1.38M/1.38M [00:02<00:00, 498k row/s]\n",
      "- Write: 1 active, 0 queued, [cpu: 1.0, objects: 256.0MB]: : 0.00 row [00:02, ? row/s]#033[A#033[A#033[A\n",
      "- Write: 0 active, 0 queued, [cpu: 0.0, objects: 283.0B]: : 0.00 row [00:02, ? row/s] #033[A#033[A#033[A\n",
      "- Write: 0 active, 0 queued, [cpu: 0.0, objects: 283.0B]: : 1.00 row [00:02, 2.77s/ row]#033[A#033[A#033[A\n",
      "- Write: 0 active, 0 queued, [cpu: 0.0, objects: 283.0B]: : 1.00 row [00:02, 2.77s/ row]#033[A#033[A#033[A\n",
      "#033[A#033[A#033[A\n",
      "- Write: 0 active, 0 queued, [cpu: 0.0, objects: 283.0B]: : 1.00 row [00:02, 2.77s/ row]\n",
      "#033[36m(_remote_exec_multi_chain pid=190, ip=10.2.245.152)#033[0m FutureWarning: The 'axis' keyword in DataFrame.groupby is deprecated and will be removed in a future version.#033[32m [repeated 119x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)#033[0m\n",
      "2024-09-11 18:26:11,823 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-09-11 18:26:11,823 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-09-11 18:26:11,823 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "2024-09-11 18:25:01,241#011INFO scripts.py:949 -- #033[37mLocal node IP#033[39m: #033[1m10.2.247.41#033[22m\n",
      "2024-09-11 18:25:02,336#011SUCC scripts.py:962 -- #033[32m--------------------#033[39m\n",
      "2024-09-11 18:25:02,336#011SUCC scripts.py:963 -- #033[32mRay runtime started.#033[39m\n",
      "2024-09-11 18:25:02,336#011SUCC scripts.py:964 -- #033[32m--------------------#033[39m\n",
      "2024-09-11 18:25:02,336#011INFO scripts.py:966 -- To terminate the Ray runtime, run\n",
      "2024-09-11 18:25:02,336#011INFO scripts.py:967 -- #033[1m  ray stop#033[22m\n",
      "2024-09-11 18:25:02,337#011INFO scripts.py:975 -- #033[36m#033[1m--block#033[22m#033[39m\n",
      "2024-09-11 18:25:02,337#011INFO scripts.py:976 -- This command will now block forever until terminated by a signal.\n",
      "2024-09-11 18:25:02,337#011INFO scripts.py:979 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.\n",
      "2024-09-11 18:27:12,454#011ERR scripts.py:1009 -- #033[31mSome Ray subprocesses exited unexpectedly:#033[39m\n",
      "2024-09-11 18:27:12,454#011ERR scripts.py:1013 -- #033[31m#033[1mraylet#033[22m#033[26m#033[39m#033[0m#033[2m [exit code=1]#033[22m#033[0m\n",
      "2024-09-11 18:27:12,454#011ERR scripts.py:1020 -- #033[31mRemaining processes will be killed.#033[39m\n",
      "2024-09-11 18:27:12,686 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-09-11 18:27:12,686 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-09-11 18:27:12,687 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "2024-09-11 18:25:00,033#011INFO scripts.py:949 -- #033[37mLocal node IP#033[39m: #033[1m10.2.245.152#033[22m\n",
      "2024-09-11 18:25:01,092#011SUCC scripts.py:962 -- #033[32m--------------------#033[39m\n",
      "2024-09-11 18:25:01,092#011SUCC scripts.py:963 -- #033[32mRay runtime started.#033[39m\n",
      "2024-09-11 18:25:01,092#011SUCC scripts.py:964 -- #033[32m--------------------#033[39m\n",
      "2024-09-11 18:25:01,092#011INFO scripts.py:966 -- To terminate the Ray runtime, run\n",
      "2024-09-11 18:25:01,093#011INFO scripts.py:967 -- #033[1m  ray stop#033[22m\n",
      "2024-09-11 18:25:01,093#011INFO scripts.py:975 -- #033[36m#033[1m--block#033[22m#033[39m\n",
      "2024-09-11 18:25:01,093#011INFO scripts.py:976 -- This command will now block forever until terminated by a signal.\n",
      "2024-09-11 18:25:01,093#011INFO scripts.py:979 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.\n",
      "2024-09-11 18:27:13,206#011ERR scripts.py:1009 -- #033[31mSome Ray subprocesses exited unexpectedly:#033[39m\n",
      "2024-09-11 18:27:13,207#011ERR scripts.py:1013 -- #033[31m#033[1mraylet#033[22m#033[26m#033[39m#033[0m#033[2m [exit code=1]#033[22m#033[0m\n",
      "2024-09-11 18:27:13,207#011ERR scripts.py:1020 -- #033[31mRemaining processes will be killed.#033[39m\n",
      "2024-09-11 18:27:13,381 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-09-11 18:27:13,381 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-09-11 18:27:13,382 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2024-09-11 18:27:34 Uploading - Uploading generated training model\n",
      "2024-09-11 18:27:34 Completed - Resource retained for reuse\n",
      "Training seconds: 570\n",
      "Billable seconds: 570\n"
     ]
    }
   ],
   "source": [
    "job.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "2024-09-11 17:27:46,008\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-09-11 17:27:46,141\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import awswrangler as wr\n",
    "# import modin.pandas as pd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wr.engine.set(\"ray\")\n",
    "# wr.memory_format.set(\"modin\")\n",
    "\n",
    "wr.engine.set(\"ray\")\n",
    "wr.memory_format.set(\"modin\")\n",
    "\n",
    "# wr.engine.set(\"python\")\n",
    "# wr.memory_format.set(\"pandas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:awswrangler.distributed.ray._core:Initializing a Ray instance\n",
      "2024-09-11 17:27:54,115\tINFO worker.py:1598 -- Connecting to existing Ray cluster at address: 172.31.42.252:9339...\n",
      "2024-09-11 17:27:54,121\tINFO worker.py:1774 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2024-09-11 17:27:54,274\tWARNING file_meta_provider.py:211 -- Skipping expansion of 1 path(s). If your paths contain directories or if file size collection is required, try rerunning this read with `meta_provider=DefaultFileMetadataProvider()`.\n",
      "2024-09-11 17:27:55,354\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-09-09_14-33-33_297169_76/logs/ray-data\n",
      "2024-09-11 17:27:55,355\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadArrowCSV]\n",
      "                                                                                                       \n",
      "✔️  Dataset execution finished in 16.60 seconds: 100%|██████████| 2.52M/2.52M [00:16<00:00, 152k row/s]         \n",
      "\n",
      "- ReadArrowCSV->SplitBlocks(64): 0 active, 0 queued, [cpu: 0.0, objects: 5.0MB]: : 2.52M row [00:16, 152k row/s]\n",
      "2024-09-11 17:28:11,973\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-09-09_14-33-33_297169_76/logs/ray-data\n",
      "2024-09-11 17:28:11,973\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadArrowCSV]\n",
      "                                                                                                      \n",
      "✔️  Dataset execution finished in 7.77 seconds: 100%|██████████| 2.52M/2.52M [00:07<00:00, 325k row/s]          \n",
      "\n",
      "- ReadArrowCSV->SplitBlocks(64): 0 active, 0 queued, [cpu: 0.0, objects: 1.7MB]: : 2.52M row [00:07, 325k row/s]\n"
     ]
    }
   ],
   "source": [
    "df = wr.s3.read_csv(\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_aggregation = df.groupby([\"TI_CU_CUSTOMER_ID\", \"TI_LN_ACCOUNT_ID\"]).agg(\n",
    "    AVERAGE_ACCOUNT_BALANCE=(\"TI_LN_BALANCE\", \"mean\"),\n",
    "    AVERAGE_MIN_PAYMENT=(\"TI_LN_VAL_PAYMENTS\", \"mean\"),\n",
    "    LATE_PAYMENTS=(\"TI_LN_NUM_MTHS_IN_ARREARS\", \"sum\"),\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modin.logger.default:Using sequential splitting in '.from_pandas()' because of some of the conditions are False: enough_elements=False; all_numeric_types=False; async_mode_on=False\n",
      "UserWarning: <function GroupBy.<lambda>> is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "Please refer to https://modin.readthedocs.io/en/stable/supported_apis/defaulting_to_pandas.html for explanation.\n",
      "INFO:modin.logger.default:Using sequential splitting in '.from_pandas()' because of some of the conditions are False: enough_elements=False; all_numeric_types=True; async_mode_on=False\n"
     ]
    }
   ],
   "source": [
    "df[\"TI_LN_DATE_OPEN\"] = pd.to_datetime(df[\"TI_LN_DATE_OPEN\"])\n",
    "df[\"months_elapsed\"] = df[\"TI_LN_ORIGINAL_TERM\"] - df[\"TI_LN_REMAINING_TERM\"]\n",
    "df[\"payment_date\"] = df.apply(\n",
    "    lambda row: row[\"TI_LN_DATE_OPEN\"] + pd.DateOffset(months=row[\"months_elapsed\"]),\n",
    "    axis=1,\n",
    ")\n",
    "monthly_balances = (\n",
    "    df.groupby([\"TI_CU_CUSTOMER_ID\", df[\"payment_date\"].dt.to_period(\"M\")])\n",
    "    .agg(\n",
    "        TOTAL_MOPNTHLY_BALANCE=(\"TI_LN_BALANCE\", \"sum\"),\n",
    "        TOTAL_ARREARS=(\"TI_LN_NUM_MTHS_IN_ARREARS\", \"sum\"),\n",
    "        NUM_ACCOUNTS=(\"TI_LN_ACCOUNT_ID\", \"count\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_balances[\"payment_date\"] = monthly_balances[\"payment_date\"].dt.to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:awswrangler.distributed.ray.modin.s3._write_text:Repartitioning frame to single partition as a strict path was defined: s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output/account_aggregation.csv. This operation is inefficient for large datasets.\n",
      "2024-09-11 17:30:35,225\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-09-09_14-33-33_297169_76/logs/ray-data\n",
      "2024-09-11 17:30:35,226\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> AllToAllOperator[Repartition] -> TaskPoolMapOperator[Write]\n",
      "Running 0: 0.00 row [00:00, ? row/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                          \n",
      "\u001b[A                                                                                                                                     \n",
      "\n",
      "\u001b[A\u001b[A                                                            \n",
      "\n",
      "\n",
      "✔️  Dataset execution finished in 1.41 seconds: : 1.00 row [00:01, 1.41s/ row]        \n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A                                                                                                                                   \n",
      "\n",
      "\u001b[A\u001b[A                                                            \n",
      "\n",
      "\n",
      "- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 0.0B], 125719 rows output: 100%|██████████| 126k/126k [00:01<00:00, 88.5k row/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                                                       \n",
      "\n",
      "\n",
      "  *- Split Repartition: 100%|██████████| 126k/126k [00:01<00:00, 88.2k row/s]         \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "- Write: 0 active, 0 queued, [cpu: 0.0, objects: 0.0B]: : 1.00 row [00:01, 1.43s/ row]\n",
      "WARNING:awswrangler.distributed.ray.modin.s3._write_text:Repartitioning frame to single partition as a strict path was defined: s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output/monthly_balances.csv. This operation is inefficient for large datasets.\n",
      "2024-09-11 17:30:36,855\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-09-09_14-33-33_297169_76/logs/ray-data\n",
      "2024-09-11 17:30:36,856\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> AllToAllOperator[Repartition] -> TaskPoolMapOperator[Write]\n",
      "Running 0: 0.00 row [00:00, ? row/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Running: 1/32 CPU, 0/0 GPU, 382.1MB/8.4GB object_store_memory: : 0.00 row [00:01, ? row/s]\n",
      "\n",
      "                                                                                                    \n",
      "\u001b[A                                                                                                                                          \n",
      "\n",
      "\u001b[A\u001b[A                                                            \n",
      "\n",
      "\n",
      "✔️  Dataset execution finished in 2.55 seconds: 100%|██████████| 1.00/1.00 [00:02<00:00, 2.55s/ row]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A                                                                                                                                       \n",
      "\n",
      "\u001b[A\u001b[A                                                            \n",
      "\n",
      "\n",
      "- Repartition: 0 active, 0 queued, [cpu: 0.0, objects: 0.0B], 1380778 rows output: 100%|██████████| 1.38M/1.38M [00:02<00:00, 540k row/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                                                        \n",
      "\n",
      "\n",
      "  *- Split Repartition: 100%|██████████| 1.38M/1.38M [00:02<00:00, 538k row/s]        \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "- Write: 0 active, 0 queued, [cpu: 0.0, objects: 287.0B]: : 1.00 row [00:02, 2.57s/ row]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output/monthly_balances.csv'],\n",
       " 'partitions_values': {}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.s3.to_csv(account_aggregation, \"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output/account_aggregation.csv\")\n",
    "wr.s3.to_csv(monthly_balances, \"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/aggregation-job/output/monthly_balances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
