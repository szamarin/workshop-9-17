{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uqq duckdb\n",
    "%pip install -Uqq duckdb-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# connect to an existing database, or create one if it doesn't exist\n",
    "conn = duckdb.connect(\"loan_data.duckdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TI_CU_CUSTOMER_ID</th>\n",
       "      <th>TI_CU_DATE_OF_BIRTH</th>\n",
       "      <th>TI_CU_DATE_FIRST_REL</th>\n",
       "      <th>TI_CU_CUST_TYPE</th>\n",
       "      <th>TI_CU_NUM_CURR_ACCT</th>\n",
       "      <th>TI_CU_NUM_REV_ACCT</th>\n",
       "      <th>TI_CU_NUM_MTGE_ACCT</th>\n",
       "      <th>TI_CU_NUM_LOAN_ACCT</th>\n",
       "      <th>TI_CU_NUM_DEP_ACCT</th>\n",
       "      <th>TI_LN_ACCOUNT_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>TI_LN_REMAINING_TERM</th>\n",
       "      <th>TI_LN_BLOCK_CODE</th>\n",
       "      <th>TI_LN_BALANCE</th>\n",
       "      <th>TI_LN_INSTALLMENT_DUE</th>\n",
       "      <th>TI_LN_VAL_PAYMENTS</th>\n",
       "      <th>TI_LN_VAL_ARREARS</th>\n",
       "      <th>TI_LN_VAL_INTEREST</th>\n",
       "      <th>TI_LN_VAL_TOTAL_FEES</th>\n",
       "      <th>TI_LN_NUM_MTHS_IN_ARREARS</th>\n",
       "      <th>TI_LN_FINAL_CHARGE_CYCLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_1</td>\n",
       "      <td>1947-10-31</td>\n",
       "      <td>1985-05-22</td>\n",
       "      <td>310</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>C_1_LN_1</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>412</td>\n",
       "      <td>265</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_1</td>\n",
       "      <td>1947-10-31</td>\n",
       "      <td>1985-05-22</td>\n",
       "      <td>310</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>C_1_LN_1</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>943</td>\n",
       "      <td>279</td>\n",
       "      <td>87</td>\n",
       "      <td>200</td>\n",
       "      <td>218</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_1</td>\n",
       "      <td>1947-10-31</td>\n",
       "      <td>1985-05-22</td>\n",
       "      <td>310</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>C_1_LN_1</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>292</td>\n",
       "      <td>69</td>\n",
       "      <td>400</td>\n",
       "      <td>276</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_1</td>\n",
       "      <td>1947-10-31</td>\n",
       "      <td>1985-05-22</td>\n",
       "      <td>310</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>C_1_LN_1</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>104</td>\n",
       "      <td>36</td>\n",
       "      <td>600</td>\n",
       "      <td>134</td>\n",
       "      <td>127</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_1</td>\n",
       "      <td>1947-10-31</td>\n",
       "      <td>1985-05-22</td>\n",
       "      <td>310</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>C_1_LN_1</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>97</td>\n",
       "      <td>283</td>\n",
       "      <td>800</td>\n",
       "      <td>177</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  TI_CU_CUSTOMER_ID TI_CU_DATE_OF_BIRTH TI_CU_DATE_FIRST_REL  TI_CU_CUST_TYPE  \\\n",
       "0               C_1          1947-10-31           1985-05-22              310   \n",
       "1               C_1          1947-10-31           1985-05-22              310   \n",
       "2               C_1          1947-10-31           1985-05-22              310   \n",
       "3               C_1          1947-10-31           1985-05-22              310   \n",
       "4               C_1          1947-10-31           1985-05-22              310   \n",
       "\n",
       "   TI_CU_NUM_CURR_ACCT  TI_CU_NUM_REV_ACCT  TI_CU_NUM_MTGE_ACCT  \\\n",
       "0                   11                   4                    5   \n",
       "1                   11                   4                    5   \n",
       "2                   11                   4                    5   \n",
       "3                   11                   4                    5   \n",
       "4                   11                   4                    5   \n",
       "\n",
       "   TI_CU_NUM_LOAN_ACCT  TI_CU_NUM_DEP_ACCT TI_LN_ACCOUNT_ID  ...  \\\n",
       "0                    3                   4         C_1_LN_1  ...   \n",
       "1                    3                   4         C_1_LN_1  ...   \n",
       "2                    3                   4         C_1_LN_1  ...   \n",
       "3                    3                   4         C_1_LN_1  ...   \n",
       "4                    3                   4         C_1_LN_1  ...   \n",
       "\n",
       "  TI_LN_REMAINING_TERM TI_LN_BLOCK_CODE TI_LN_BALANCE  TI_LN_INSTALLMENT_DUE  \\\n",
       "0                   36                0           412                    265   \n",
       "1                   35                0           943                    279   \n",
       "2                   34                0           270                    292   \n",
       "3                   33                0          2339                    104   \n",
       "4                   32                0           287                     97   \n",
       "\n",
       "   TI_LN_VAL_PAYMENTS  TI_LN_VAL_ARREARS TI_LN_VAL_INTEREST  \\\n",
       "0                  16                  0                212   \n",
       "1                  87                200                218   \n",
       "2                  69                400                276   \n",
       "3                  36                600                134   \n",
       "4                 283                800                177   \n",
       "\n",
       "   TI_LN_VAL_TOTAL_FEES  TI_LN_NUM_MTHS_IN_ARREARS TI_LN_FINAL_CHARGE_CYCLE  \n",
       "0                   121                          0                        0  \n",
       "1                    73                          1                        0  \n",
       "2                    25                          2                        0  \n",
       "3                   127                          3                        0  \n",
       "4                     9                          4                        0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can query data using SQL directly from the CSV file\n",
    "sample_df = conn.execute(\"SELECT * FROM 'data/ln_large.csv' LIMIT 5\").df()\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TI_CU_CUSTOMER_ID                       object\n",
       "TI_CU_DATE_OF_BIRTH             datetime64[us]\n",
       "TI_CU_DATE_FIRST_REL            datetime64[us]\n",
       "TI_CU_CUST_TYPE                          int64\n",
       "TI_CU_NUM_CURR_ACCT                      int64\n",
       "TI_CU_NUM_REV_ACCT                       int64\n",
       "TI_CU_NUM_MTGE_ACCT                      int64\n",
       "TI_CU_NUM_LOAN_ACCT                      int64\n",
       "TI_CU_NUM_DEP_ACCT                       int64\n",
       "TI_LN_ACCOUNT_ID                        object\n",
       "TI_LN_DATE_OPEN                 datetime64[us]\n",
       "TI_LN_DATE_CLOSED                       object\n",
       "TI_LN_WRITE_OFF_DATE                    object\n",
       "TI_LN_REASON_CLOSED                      int64\n",
       "TI_LN_NUM_PARTIES                        int64\n",
       "TI_LN_ACCOUNT_TYPE                       int64\n",
       "TI_LN_PURPOSE                           object\n",
       "TI_LN_ORIGINAL_TERM                      int64\n",
       "TI_LN_ORIGINAL_LOAN_AMOUNT               int64\n",
       "TI_LN_DATE_FIRST_INSTALLMENT    datetime64[us]\n",
       "TI_LN_PAYMENT_FREQUENCY                  int64\n",
       "TI_LN_PAYMENT_METHOD                     int64\n",
       "TI_LN_VAL_FEES                           int64\n",
       "TI_LN_DATE_DUE                  datetime64[us]\n",
       "TI_LN_REMAINING_TERM                     int64\n",
       "TI_LN_BLOCK_CODE                         int64\n",
       "TI_LN_BALANCE                            int64\n",
       "TI_LN_INSTALLMENT_DUE                    int64\n",
       "TI_LN_VAL_PAYMENTS                       int64\n",
       "TI_LN_VAL_ARREARS                        int64\n",
       "TI_LN_VAL_INTEREST                       int64\n",
       "TI_LN_VAL_TOTAL_FEES                     int64\n",
       "TI_LN_NUM_MTHS_IN_ARREARS                int64\n",
       "TI_LN_FINAL_CHARGE_CYCLE                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also validate how well the data types were inferred from the CSV file\n",
    "sample_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f083a94bc30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for better performance, we can ingest the CSV file into a datble within the database\n",
    "conn.execute(\"create table if not exists loan_data as select * from 'data/ln_large.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loan_data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name\n",
       "0  loan_data"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate that the table was created\n",
    "conn.execute(\"show tables\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_star()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2522277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_star()\n",
       "0       2522277"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can now query the data from the table\n",
    "conn.execute(\"select count(*) from loan_data\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try a more complex query to profile the numeric columns\n",
    "profile_numeric_sql = \"\"\"\n",
    "WITH percentiles AS (\n",
    "    SELECT\n",
    "        'ti_ln_remaining_term' AS column_name,\n",
    "        MIN(ti_ln_remaining_term) AS min_value,\n",
    "        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY ti_ln_remaining_term) AS p25,\n",
    "        PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY ti_ln_remaining_term) AS p50,\n",
    "        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY ti_ln_remaining_term) AS p75,\n",
    "        MAX(ti_ln_remaining_term) AS max_value\n",
    "    FROM loan_data\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'ti_ln_balance' AS column_name,\n",
    "        MIN(ti_ln_balance) AS min_value,\n",
    "        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY ti_ln_balance) AS p25,\n",
    "        PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY ti_ln_balance) AS p50,\n",
    "        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY ti_ln_balance) AS p75,\n",
    "        MAX(ti_ln_balance) AS max_value\n",
    "    FROM loan_data\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'ti_ln_installment_due' AS column_name,\n",
    "        MIN(ti_ln_installment_due) AS min_value,\n",
    "        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY ti_ln_installment_due) AS p25,\n",
    "        PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY ti_ln_installment_due) AS p50,\n",
    "        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY ti_ln_installment_due) AS p75,\n",
    "        MAX(ti_ln_installment_due) AS max_value\n",
    "    FROM loan_data\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'ti_ln_val_payments' AS column_name,\n",
    "        MIN(ti_ln_val_payments) AS min_value,\n",
    "        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY ti_ln_val_payments) AS p25,\n",
    "        PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY ti_ln_val_payments) AS p50,\n",
    "        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY ti_ln_val_payments) AS p75,\n",
    "        MAX(ti_ln_val_payments) AS max_value\n",
    "    FROM loan_data\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'ti_ln_val_interest' AS column_name,\n",
    "        MIN(ti_ln_val_interest) AS min_value,\n",
    "        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY ti_ln_val_interest) AS p25,\n",
    "        PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY ti_ln_val_interest) AS p50,\n",
    "        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY ti_ln_val_interest) AS p75,\n",
    "        MAX(ti_ln_val_interest) AS max_value\n",
    "    FROM loan_data\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'ti_ln_val_total_fees' AS column_name,\n",
    "        MIN(ti_ln_val_total_fees) AS min_value,\n",
    "        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY ti_ln_val_total_fees) AS p25,\n",
    "        PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY ti_ln_val_total_fees) AS p50,\n",
    "        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY ti_ln_val_total_fees) AS p75,\n",
    "        MAX(ti_ln_val_total_fees) AS max_value\n",
    "    FROM loan_data\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'ti_ln_final_charge_cycle' AS column_name,\n",
    "        MIN(ti_ln_final_charge_cycle) AS min_value,\n",
    "        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY ti_ln_final_charge_cycle) AS p25,\n",
    "        PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY ti_ln_final_charge_cycle) AS p50,\n",
    "        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY ti_ln_final_charge_cycle) AS p75,\n",
    "        MAX(ti_ln_final_charge_cycle) AS max_value\n",
    "    FROM loan_data\n",
    ")\n",
    "SELECT * FROM percentiles;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>min_value</th>\n",
       "      <th>p25</th>\n",
       "      <th>p50</th>\n",
       "      <th>p75</th>\n",
       "      <th>max_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ti_ln_remaining_term</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ti_ln_balance</td>\n",
       "      <td>0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ti_ln_installment_due</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ti_ln_val_payments</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ti_ln_val_interest</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ti_ln_val_total_fees</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ti_ln_final_charge_cycle</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                column_name  min_value    p25     p50     p75  max_value\n",
       "0      ti_ln_remaining_term          1   13.0    25.0    39.0         60\n",
       "1             ti_ln_balance          0  749.0  1498.0  2250.0       2999\n",
       "2     ti_ln_installment_due          0   75.0   150.0   224.0        299\n",
       "3        ti_ln_val_payments          0   75.0   149.0   225.0        299\n",
       "4        ti_ln_val_interest          0   74.0   149.0   225.0        299\n",
       "5      ti_ln_val_total_fees          0   75.0   149.0   224.0        299\n",
       "6  ti_ln_final_charge_cycle          0    0.0     0.0     0.0        199"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute(profile_numeric_sql).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f083a94bc30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also use duckdb to convert the data to parquet format for better performance and interoperability\n",
    "conn.execute(\n",
    "    \"\"\"copy (select *, \n",
    "    year(TI_LN_DATE_OPEN) as TI_LN_DATE_OPEN_YEAR, \n",
    "    month(ti_ln_date_open) as TI_LN_DATE_OPEN_MONTH \n",
    "    from loan_data) \n",
    "    to 'parquet_output' \n",
    "    (FORMAT PARQUET, PARTITION_BY (TI_LN_DATE_OPEN_YEAR, TI_LN_DATE_OPEN_MONTH), OVERWRITE_OR_IGNORE true)\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from pathlib import Path\n",
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "bucket = sess.default_bucket()  # default bucket name\n",
    "account_id = sess.account_id() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = PyTorchProcessor(\n",
    "    framework_version='2.2',\n",
    "    py_version='py310',\n",
    "    role=role,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=1,\n",
    "    base_job_name='processing-job'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_csv_data = (\n",
    "    \"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/csv/ln_large.csv\"\n",
    ")\n",
    "\n",
    "s3_output_location = f\"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/processing_output\"\n",
    "\n",
    "job_inputs = [\n",
    "    ProcessingInput(\n",
    "        input_name=\"data\",\n",
    "        source=s3_csv_data,                     # the S3 location from where the data will be read and copied to the processing instance\n",
    "        destination=\"/opt/ml/processing/input\", # the folder inside the processing instance where the data will be copied to\n",
    "    )\n",
    "]\n",
    "\n",
    "job_outputs = [\n",
    "    ProcessingOutput(\n",
    "        output_name=\"data_structured\",\n",
    "        source=\"/opt/ml/processing/output\",   # the folder inside the processing instance where script the output will be written to\n",
    "        destination=s3_output_location,       # the S3 location where the output will be stored\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name processing-job-2024-09-09-15-28-46-164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............WARNING: Skipping typing as it is not installed.\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Collecting duckdb (from -r requirements.txt (line 1))\n",
      "  Downloading duckdb-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (762 bytes)\n",
      "Collecting duckdb-engine (from -r requirements.txt (line 2))\n",
      "  Downloading duckdb_engine-0.13.2-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from duckdb-engine->-r requirements.txt (line 2)) (23.2)\n",
      "Collecting sqlalchemy>=1.3.22 (from duckdb-engine->-r requirements.txt (line 2))\n",
      "  Downloading SQLAlchemy-2.0.34-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.22->duckdb-engine->-r requirements.txt (line 2)) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.22->duckdb-engine->-r requirements.txt (line 2)) (3.0.3)\n",
      "Downloading duckdb-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.1 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.1/20.1 MB 58.0 MB/s eta 0:00:00\n",
      "Downloading duckdb_engine-0.13.2-py3-none-any.whl (47 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.4/47.4 kB 7.8 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.34-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 106.3 MB/s eta 0:00:00\n",
      "Installing collected packages: sqlalchemy, duckdb, duckdb-engine\n",
      "Successfully installed duckdb-1.1.0 duckdb-engine-0.13.2 sqlalchemy-2.0.34\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job = processor.run(\n",
    "    code=\"convert_to_parquet.py\",\n",
    "    source_dir=\"processing_script\",\n",
    "    inputs=job_inputs,\n",
    "    outputs=job_outputs,\n",
    "    arguments=[\n",
    "        \"--input_dir\",\n",
    "        \"/opt/ml/processing/input\",\n",
    "        \"--output_dir\",\n",
    "        \"/opt/ml/processing/output\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-09 15:31:27    2375015 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2019/TI_LN_DATE_OPEN_MONTH=1/data_0.parquet\n",
      "2024-09-09 15:31:27    2058040 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2019/TI_LN_DATE_OPEN_MONTH=10/data_0.parquet\n",
      "2024-09-09 15:31:27    1944341 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2019/TI_LN_DATE_OPEN_MONTH=11/data_0.parquet\n",
      "2024-09-09 15:31:27    2035199 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2019/TI_LN_DATE_OPEN_MONTH=12/data_0.parquet\n",
      "2024-09-09 15:31:27    2110977 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2019/TI_LN_DATE_OPEN_MONTH=2/data_0.parquet\n",
      "2024-09-09 15:31:27    2267208 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2019/TI_LN_DATE_OPEN_MONTH=3/data_0.parquet\n",
      "2024-09-09 15:31:27    2168262 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2019/TI_LN_DATE_OPEN_MONTH=4/data_0.parquet\n",
      "2024-09-09 15:31:27    2119934 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2019/TI_LN_DATE_OPEN_MONTH=5/data_0.parquet\n",
      "2024-09-09 15:31:27    2193583 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2019/TI_LN_DATE_OPEN_MONTH=6/data_0.parquet\n",
      "2024-09-09 15:31:27    2080861 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2019/TI_LN_DATE_OPEN_MONTH=7/data_0.parquet\n",
      "2024-09-09 15:31:27    2143904 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2019/TI_LN_DATE_OPEN_MONTH=8/data_0.parquet\n",
      "2024-09-09 15:31:27    2031755 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2019/TI_LN_DATE_OPEN_MONTH=9/data_0.parquet\n",
      "2024-09-09 15:31:27    2013379 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2020/TI_LN_DATE_OPEN_MONTH=1/data_0.parquet\n",
      "2024-09-09 15:31:27    1608204 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2020/TI_LN_DATE_OPEN_MONTH=10/data_0.parquet\n",
      "2024-09-09 15:31:27    1556402 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2020/TI_LN_DATE_OPEN_MONTH=11/data_0.parquet\n",
      "2024-09-09 15:31:27    1608546 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2020/TI_LN_DATE_OPEN_MONTH=12/data_0.parquet\n",
      "2024-09-09 15:31:27    1779629 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2020/TI_LN_DATE_OPEN_MONTH=2/data_0.parquet\n",
      "2024-09-09 15:31:27    1935909 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2020/TI_LN_DATE_OPEN_MONTH=3/data_0.parquet\n",
      "2024-09-09 15:31:27    1810770 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2020/TI_LN_DATE_OPEN_MONTH=4/data_0.parquet\n",
      "2024-09-09 15:31:27    1819426 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2020/TI_LN_DATE_OPEN_MONTH=5/data_0.parquet\n",
      "2024-09-09 15:31:27    1712394 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2020/TI_LN_DATE_OPEN_MONTH=6/data_0.parquet\n",
      "2024-09-09 15:31:27    1759964 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2020/TI_LN_DATE_OPEN_MONTH=7/data_0.parquet\n",
      "2024-09-09 15:31:27    1677319 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2020/TI_LN_DATE_OPEN_MONTH=8/data_0.parquet\n",
      "2024-09-09 15:31:27    1655236 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2020/TI_LN_DATE_OPEN_MONTH=9/data_0.parquet\n",
      "2024-09-09 15:31:27    1568907 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2021/TI_LN_DATE_OPEN_MONTH=1/data_0.parquet\n",
      "2024-09-09 15:31:27    1064524 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2021/TI_LN_DATE_OPEN_MONTH=10/data_0.parquet\n",
      "2024-09-09 15:31:27    1031042 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2021/TI_LN_DATE_OPEN_MONTH=11/data_0.parquet\n",
      "2024-09-09 15:31:27     994578 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2021/TI_LN_DATE_OPEN_MONTH=12/data_0.parquet\n",
      "2024-09-09 15:31:27    1319299 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2021/TI_LN_DATE_OPEN_MONTH=2/data_0.parquet\n",
      "2024-09-09 15:31:27    1481043 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2021/TI_LN_DATE_OPEN_MONTH=3/data_0.parquet\n",
      "2024-09-09 15:31:27    1394999 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2021/TI_LN_DATE_OPEN_MONTH=4/data_0.parquet\n",
      "2024-09-09 15:31:27    1315635 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2021/TI_LN_DATE_OPEN_MONTH=5/data_0.parquet\n",
      "2024-09-09 15:31:27    1270768 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2021/TI_LN_DATE_OPEN_MONTH=6/data_0.parquet\n",
      "2024-09-09 15:31:27    1265465 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2021/TI_LN_DATE_OPEN_MONTH=7/data_0.parquet\n",
      "2024-09-09 15:31:27    1236357 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2021/TI_LN_DATE_OPEN_MONTH=8/data_0.parquet\n",
      "2024-09-09 15:31:27    1072530 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2021/TI_LN_DATE_OPEN_MONTH=9/data_0.parquet\n",
      "2024-09-09 15:31:27     913791 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2022/TI_LN_DATE_OPEN_MONTH=1/data_0.parquet\n",
      "2024-09-09 15:31:27     385219 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2022/TI_LN_DATE_OPEN_MONTH=10/data_0.parquet\n",
      "2024-09-09 15:31:27     317186 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2022/TI_LN_DATE_OPEN_MONTH=11/data_0.parquet\n",
      "2024-09-09 15:31:27     228560 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2022/TI_LN_DATE_OPEN_MONTH=12/data_0.parquet\n",
      "2024-09-09 15:31:27     786573 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2022/TI_LN_DATE_OPEN_MONTH=2/data_0.parquet\n",
      "2024-09-09 15:31:27     827449 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2022/TI_LN_DATE_OPEN_MONTH=3/data_0.parquet\n",
      "2024-09-09 15:31:27     724756 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2022/TI_LN_DATE_OPEN_MONTH=4/data_0.parquet\n",
      "2024-09-09 15:31:27     635787 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2022/TI_LN_DATE_OPEN_MONTH=5/data_0.parquet\n",
      "2024-09-09 15:31:27     581010 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2022/TI_LN_DATE_OPEN_MONTH=6/data_0.parquet\n",
      "2024-09-09 15:31:27     562317 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2022/TI_LN_DATE_OPEN_MONTH=7/data_0.parquet\n",
      "2024-09-09 15:31:27     513589 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2022/TI_LN_DATE_OPEN_MONTH=8/data_0.parquet\n",
      "2024-09-09 15:31:27     434140 fico_ml_workshop/data/processing_output/TI_LN_DATE_OPEN_YEAR=2022/TI_LN_DATE_OPEN_MONTH=9/data_0.parquet\n",
      "2024-09-06 19:47:00  386420064 fico_ml_workshop/data/processing_output/out.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $s3_output_location/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.remote_function import remote\n",
    "from sagemaker import image_uris\n",
    "\n",
    "image_uri = image_uri = image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    image_scope=\"training\",\n",
    "    region=region,\n",
    "    version=\"2.3\",\n",
    "    py_version=\"py311\",\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")\n",
    "\n",
    "\n",
    "@remote(\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    dependencies=\"processing_script/requirements.txt\",\n",
    "    image_uri=image_uri,\n",
    ")\n",
    "def convert_to_parquet(input_s3_path: str, output_s3_path: str):\n",
    "\n",
    "    conn = duckdb.connect(\"temp_data.duckdb\")\n",
    "\n",
    "    # configure S3 access\n",
    "    conn.execute(\n",
    "        \"\"\"CREATE SECRET s3_access (\n",
    "           TYPE S3,\n",
    "           PROVIDER CREDENTIAL_CHAIN\n",
    "        );\"\"\"\n",
    "    )\n",
    "\n",
    "    # create a temporary table from data in S3\n",
    "    conn.execute(f\"CREATE TABLE temp_table AS SELECT * FROM '{input_s3_path}'\")\n",
    "\n",
    "    # convert the data to parquet format\n",
    "    conn.execute(\n",
    "        f\"\"\"copy (select *, \n",
    "    year(TI_LN_DATE_OPEN) as TI_LN_DATE_OPEN_YEAR, \n",
    "    month(ti_ln_date_open) as TI_LN_DATE_OPEN_MONTH \n",
    "    from temp_table) \n",
    "    to '{output_s3_path}' \n",
    "    (FORMAT PARQUET, PARTITION_BY (TI_LN_DATE_OPEN_YEAR, TI_LN_DATE_OPEN_MONTH), OVERWRITE_OR_IGNORE true)\"\"\"\n",
    "    )\n",
    "\n",
    "    return output_s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 16:46:28,931 sagemaker.remote_function INFO     Serializing function code to s3://sagemaker-us-east-1-152804913371/convert-to-parquet-2024-09-09-16-46-28-930/function\n",
      "2024-09-09 16:46:29,054 sagemaker.remote_function INFO     Serializing function arguments to s3://sagemaker-us-east-1-152804913371/convert-to-parquet-2024-09-09-16-46-28-930/arguments\n",
      "2024-09-09 16:46:29,352 sagemaker.remote_function INFO     Copied dependencies file at 'processing_script/requirements.txt' to '/tmp/tmpakwarjfl/temp_workspace/sagemaker_remote_function_workspace/requirements.txt'\n",
      "2024-09-09 16:46:29,353 sagemaker.remote_function INFO     Successfully created workdir archive at '/tmp/tmpakwarjfl/workspace.zip'\n",
      "2024-09-09 16:46:29,385 sagemaker.remote_function INFO     Successfully uploaded workdir to 's3://sagemaker-us-east-1-152804913371/convert-to-parquet-2024-09-09-16-46-28-930/sm_rf_user_ws/workspace.zip'\n",
      "2024-09-09 16:46:29,386 sagemaker.remote_function INFO     Creating job: convert-to-parquet-2024-09-09-16-46-28-930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-09 16:46:29 Starting - Starting the training job...\n",
      "2024-09-09 16:46:44 Starting - Preparing the instances for training...\n",
      "2024-09-09 16:47:07 Downloading - Downloading input data...\n",
      "2024-09-09 16:47:33 Downloading - Downloading the training image.....INFO: CONDA_PKGS_DIRS is set to '/opt/ml/sagemaker/warmpoolcache/sm_remotefunction_user_dependencies_cache/conda/pkgs'\n",
      "INFO: PIP_CACHE_DIR is set to '/opt/ml/sagemaker/warmpoolcache/sm_remotefunction_user_dependencies_cache/pip'\n",
      "INFO: Bootstraping runtime environment.\n",
      "2024-09-09 16:48:42,999 sagemaker.remote_function INFO     Successfully unpacked workspace archive at '/'.\n",
      "2024-09-09 16:48:42,999 sagemaker.remote_function INFO     '/sagemaker_remote_function_workspace/pre_exec.sh' does not exist. Assuming no pre-execution commands to run\n",
      "2024-09-09 16:48:43,000 sagemaker.remote_function INFO     Running command: '/opt/conda/bin/python -m pip install -r /sagemaker_remote_function_workspace/requirements.txt -U' in the dir: '/' \n",
      "2024-09-09 16:48:43,557 sagemaker.remote_function INFO     Collecting duckdb (from -r /sagemaker_remote_function_workspace/requirements.txt (line 1))\n",
      "2024-09-09 16:48:43,587 sagemaker.remote_function INFO       Downloading duckdb-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (762 bytes)\n",
      "2024-09-09 16:48:43,622 sagemaker.remote_function INFO     Collecting duckdb-engine (from -r /sagemaker_remote_function_workspace/requirements.txt (line 2))\n",
      "2024-09-09 16:48:43,627 sagemaker.remote_function INFO       Downloading duckdb_engine-0.13.2-py3-none-any.whl.metadata (7.9 kB)\n",
      "2024-09-09 16:48:43,638 sagemaker.remote_function INFO     Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.11/site-packages (from duckdb-engine->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (23.2)\n",
      "2024-09-09 16:48:43,959 sagemaker.remote_function INFO     Collecting sqlalchemy>=1.3.22 (from duckdb-engine->-r /sagemaker_remote_function_workspace/requirements.txt (line 2))\n",
      "2024-09-09 16:48:43,963 sagemaker.remote_function INFO       Downloading SQLAlchemy-2.0.34-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "2024-09-09 16:48:43,979 sagemaker.remote_function INFO     Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy>=1.3.22->duckdb-engine->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (4.11.0)\n",
      "2024-09-09 16:48:43,980 sagemaker.remote_function INFO     Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy>=1.3.22->duckdb-engine->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (3.0.3)\n",
      "2024-09-09 16:48:43,986 sagemaker.remote_function INFO     Downloading duckdb-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.1 MB)\n",
      "2024-09-09 16:48:44,173 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.1/20.1 MB 115.9 MB/s eta 0:00:00\n",
      "2024-09-09 16:48:44,178 sagemaker.remote_function INFO     Downloading duckdb_engine-0.13.2-py3-none-any.whl (47 kB)\n",
      "2024-09-09 16:48:44,190 sagemaker.remote_function INFO     Downloading SQLAlchemy-2.0.34-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "2024-09-09 16:48:44,219 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 115.1 MB/s eta 0:00:00\n",
      "2024-09-09 16:48:44,526 sagemaker.remote_function INFO     Installing collected packages: sqlalchemy, duckdb, duckdb-engine\n",
      "2024-09-09 16:48:45,914 sagemaker.remote_function INFO     Successfully installed duckdb-1.1.0 duckdb-engine-0.13.2 sqlalchemy-2.0.34\n",
      "2024-09-09 16:48:46,127 sagemaker.remote_function WARNING  WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "2024-09-09 16:48:46,128 sagemaker.remote_function INFO     Command /opt/conda/bin/python -m pip install -r /sagemaker_remote_function_workspace/requirements.txt -U ran successfully\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "INFO: Changing workspace to sagemaker_remote_function_workspace.\n",
      "INFO: No conda env provided. Invoking remote function\n",
      "\n",
      "2024-09-09 16:48:34 Training - Training image download completed. Training in progress.sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "2024-09-09 16:48:48,428 sagemaker.remote_function INFO     Deserializing function code from s3://sagemaker-us-east-1-152804913371/convert-to-parquet-2024-09-09-16-46-28-930/function\n",
      "2024-09-09 16:48:48,587 sagemaker.remote_function INFO     Deserializing function arguments from s3://sagemaker-us-east-1-152804913371/convert-to-parquet-2024-09-09-16-46-28-930/arguments\n",
      "2024-09-09 16:48:48,661 sagemaker.remote_function INFO     Resolving pipeline variables\n",
      "2024-09-09 16:48:48,661 sagemaker.remote_function INFO     Invoking the function\n",
      "\n",
      "2024-09-09 16:49:30 Uploading - Uploading generated training model2024-09-09 16:49:26,833 sagemaker.remote_function INFO     Serializing the function return and uploading to s3://sagemaker-us-east-1-152804913371/convert-to-parquet-2024-09-09-16-46-28-930/results\n",
      "\n",
      "2024-09-09 16:49:38 Completed - Training job completed\n",
      "Training seconds: 151\n",
      "Billable seconds: 151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/remote_func_output'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_parquet(s3_csv_data, \"s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/remote_func_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE TI_LN_DATE_OPEN_YEAR=2019/\n",
      "                           PRE TI_LN_DATE_OPEN_YEAR=2020/\n",
      "                           PRE TI_LN_DATE_OPEN_YEAR=2021/\n",
      "                           PRE TI_LN_DATE_OPEN_YEAR=2022/\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://sagemaker-us-east-1-152804913371/fico_ml_workshop/data/remote_func_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
